buildscript {
    repositories {
        mavenCentral()
        gradlePluginPortal()
        maven {
            url = 'https://packages.confluent.io/maven/'
        }
        maven {
            url = 'https://jitpack.io'
        }
    }
    dependencies {
        classpath 'gradle.plugin.com.github.jengelman.gradle.plugins:shadow:7.0.0'
    }
}

plugins {
    id 'java'
    id 'com.google.cloud.tools.jib' version '3.3.1'
    id 'idea'
    id 'eclipse'
    id 'com.github.imflog.kafka-schema-registry-gradle-plugin' version '1.13.0'
    id 'com.github.davidmc24.gradle.plugin.avro' version '1.9.1'
}

java {
    sourceCompatibility = JavaVersion.VERSION_17
    targetCompatibility = JavaVersion.VERSION_17
}
version = '0.0.1'

repositories {
    mavenCentral()

    maven {
        url 'https://packages.confluent.io/maven'
    }
}

apply plugin: 'com.github.johnrengelman.shadow'

dependencies {
    implementation 'org.slf4j:slf4j-simple:2.0.7'
    implementation 'org.apache.kafka:kafka-clients:3.6.0'
    implementation 'org.apache.kafka:kafka-streams:3.6.0'
    implementation 'org.apache.avro:avro:1.11.1'
    implementation 'io.confluent:kafka-avro-serializer:7.5.1'
    testImplementation 'com.google.guava:guava:31.1-jre'
    testImplementation 'org.junit.jupiter:junit-jupiter-api:5.9.2'
    testRuntimeOnly 'org.junit.platform:junit-platform-launcher'
    testRuntimeOnly 'org.junit.jupiter:junit-jupiter-engine:5.9.2'
    testImplementation 'org.testcontainers:testcontainers:2.0.3'
    testImplementation 'org.hamcrest:hamcrest:2.2'
}

test {
    useJUnitPlatform()
    testLogging {
        outputs.upToDateWhen { false }
        showStandardStreams = true
        exceptionFormat = 'full'
    }
}

jar {
  manifest {
    attributes(
      'Class-Path': configurations.compileClasspath.collect { it.getName() }.join(' '),
      'Main-Class': 'io.confluent.developer.MultiEventAvroProduceConsumeApp'
    )
  }
}

shadowJar {
    archiveBaseName = 'multiple-event-types-avro-standalone'
    archiveClassifier = ''
}

schemaRegistry {
    def props = new Properties()
    def configs = file('cloud.properties')
    if (configs.exists()) {
        configs.withInputStream { props.load(it) }
        def srUrl = props.getProperty('schema.registry.url')
        def auth = props.getProperty('basic.auth.user.info').split(':')
        println 'Using Confluent properties Schema Registry endpoint:${srUrl}, username:${auth[0]},password:${auth[1]}'

        url = srUrl

        credentials {
            // username is the characters up to the ':' in the basic.auth.user.info property
            username = auth[0]
            // password is everything after ':' in the basic.auth.user.info property
            password = auth[1]
        }
    } else if (file('local.properties').exists()) {
        configs = file('local.properties')
        configs.withInputStream { props.load(it) }
        def srUrl = props.getProperty('schema.registry.url')
        println 'Using local dev properties Schema Registry endpoint:${srUrl}'
    } else {
        println 'No configs to parse yet'
    }

    // Possible types are ['JSON', 'PROTOBUF', 'AVRO']
    register {
        // paths relative to top level
        subject('pageview', 'multiple-event-types-avro/kafka/src/main/avro/pageview.avsc', 'AVRO')
        subject('purchase', 'multiple-event-types-avro/kafka/src/main/avro/purchase.avsc', 'AVRO')
        subject('avro-events-value', 'multiple-event-types-avro/kafka/src/main/avro/all-events.avsc', 'AVRO')
                .addReference('io.confluent.developer.avro.Pageview', 'pageview', 1)
                .addReference('io.confluent.developer.avro.Purchase', 'purchase', 1)
    }

}
